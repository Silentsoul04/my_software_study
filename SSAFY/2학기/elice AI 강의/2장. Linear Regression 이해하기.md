# 2장. Linear Regression 이해하기

## Linear Regression

- 지도학습에 적용되는 분석법이다. Classification은 Binary 분석이다. (이 그림이 자동차냐 아니냐) 하지만 Linear Regression은 데이터가 주어졌을 때, 그 결과를 실수로 표현할 수 있다. (값이 6.02이다, 5.7이다.)

- 집에 평수에 대한 가격 예측 / 손님이 매장에서 돈을 얼마나 쓸 것인가?

- Regression에서 가장 간단한 형태가 Linear Regression이다.

- x축에 대해서 y값을 잘 예측할 수 있도록 Line을 그어주는 것이다.

- 그래서 있는 데이터를 기준으로 기울기를 찾아야 없는 데이터 셋에 대해서 x축에 관한 y축 값을 알아낼 수 있다.

- 이걸 감으로 할 수 없으니 수식으로 해결해야한다.
  $$
  y=ax+b
  $$

  $$
  y=w_1x+w_0
  $$

- 사실 2차원이라서 직선이 그어지는데, 선형이 아닐 수도 있다. (non-linear relationships) 이 것도 모델링을 할 수 있다. 실제로 다뤄보진 않을 것이다.

- 사실 차원이 14 ~ 20까지 점점 커지면 그닥 사용하는 것이 무의미하다.

- Linear Regression에서 중요한거는 위의 값에서 w가 뭔지 찾는 것이 중요하다. 때려 넣으면 안됨, 그럼 어떻게 찾을까?? 적합한 w를 찾으려면 RSS(Residual Sum of squares)를 사용하는 것이 좋다. 실제 데이터 값과 선형에서의 y 값의 오차를 구하는 것이다. 그 오차를 작게 만드는 w가 제일 적합한 w이다.

- 근데 w를 찾다가 overfit이 일어날 수 있다. 그렇기에 이걸 단순, 심플화 시키는 것이 Regularization이다. w가 비 이상적으로 큰 값, 작은 값들에 대해서 패널티를 주는 것이다. 단순히 w를 찾는 것이 아니라 여기에 더해서 비 이상적인 w를 처리하는 것이 Regularization이다.

- Regularization은 모든 머신러닝 모델에서 중요하다. 그 방법은 여러가지 있는데, 제일 단순한 것은 Data를 많이 쓰면 된다. 만약 data가 적으면 그 것을 어거지로 fitting하다가 overfitting이 된다. 데이터가 많으면 훨씬 Simple 한 라인이 나온다.

- 참고로 training data에 대해선 예측을 잘 해야한다. 우리가 외운 문제를 더 잘 푸는거 처럼 또한, 에러가 없다가 생기면 그 것은 overfitting이 되어 있다는 뜻이다.